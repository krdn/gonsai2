name: Performance

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main, develop]
  workflow_dispatch:

concurrency:
  group: perf-${{ github.ref }}
  cancel-in-progress: true

permissions:
  contents: read
  pull-requests: write
  issues: write

jobs:
  lighthouse:
    name: Lighthouse CI
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20.x'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Build Frontend
        run: |
          cd apps/frontend
          npm ci
          npm run build
        env:
          NEXT_PUBLIC_API_URL: http://localhost:3000
          NEXT_PUBLIC_WS_URL: ws://localhost:3001

      - name: Run Lighthouse CI
        uses: treosh/lighthouse-ci-action@v12
        with:
          configPath: ./lighthouserc.json
          uploadArtifacts: true
          temporaryPublicStorage: true

      - name: Format lighthouse score
        id: format_lighthouse_score
        uses: actions/github-script@v7
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const fs = require('fs');
            const results = JSON.parse(fs.readFileSync('.lighthouseci/manifest.json'));

            let comment = '## âš¡ Lighthouse Performance Report\n\n';

            for (const result of results) {
              const { url, summary } = result;
              const formatScore = (score) => Math.round(score * 100);

              comment += `### ${url}\n\n`;
              comment += '| Metric | Score |\n';
              comment += '|--------|-------|\n';
              comment += `| Performance | ${formatScore(summary.performance)} |\n`;
              comment += `| Accessibility | ${formatScore(summary.accessibility)} |\n`;
              comment += `| Best Practices | ${formatScore(summary['best-practices'])} |\n`;
              comment += `| SEO | ${formatScore(summary.seo)} |\n`;
              comment += '\n';
            }

            core.setOutput('comment', comment);

      - name: Comment PR
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const comment = `${{ steps.format_lighthouse_score.outputs.comment }}`;

            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });

  bundle-analysis:
    name: Bundle Size Analysis
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20.x'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Build with bundle analyzer
        run: |
          cd apps/frontend
          npm ci
          ANALYZE=true npm run build
        env:
          NEXT_PUBLIC_API_URL: http://localhost:3000
          NEXT_PUBLIC_WS_URL: ws://localhost:3001

      - name: Upload bundle stats
        uses: actions/upload-artifact@v4
        with:
          name: bundle-stats
          path: |
            apps/frontend/.next/analyze/
            apps/frontend/.next/stats.json
          if-no-files-found: ignore

      - name: Check bundle size
        id: bundle-size
        run: |
          if [ -f "apps/frontend/.next/required-server-files.json" ]; then
            TOTAL_SIZE=$(du -sh apps/frontend/.next | cut -f1)
            echo "size=$TOTAL_SIZE" >> $GITHUB_OUTPUT
            echo "## ðŸ“¦ Bundle Size: $TOTAL_SIZE" >> $GITHUB_STEP_SUMMARY
          fi

  api-benchmark:
    name: API Performance Benchmark
    runs-on: ubuntu-latest

    services:
      mongodb:
        image: mongo:7
        env:
          MONGO_INITDB_ROOT_USERNAME: admin
          MONGO_INITDB_ROOT_PASSWORD: testpassword
        ports:
          - 27017:27017
        options: >-
          --health-cmd "mongosh --eval 'db.adminCommand({ping: 1})'"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

      redis:
        image: redis:7-alpine
        ports:
          - 6379:6379
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20.x'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Build Backend
        run: npx tsc -p apps/backend/tsconfig.build.json

      - name: Start Backend Server
        run: |
          npm run server &
          sleep 10
        env:
          NODE_ENV: production
          PORT: 3000
          MONGODB_URI: mongodb://admin:testpassword@localhost:27017/gonsai2_test?authSource=admin
          REDIS_HOST: localhost
          REDIS_PORT: 6379

      - name: Install k6
        run: |
          sudo gpg -k
          sudo gpg --no-default-keyring --keyring /usr/share/keyrings/k6-archive-keyring.gpg --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys C5AD17C747E3415A3642D57D77C6C491D6AC1D69
          echo "deb [signed-by=/usr/share/keyrings/k6-archive-keyring.gpg] https://dl.k6.io/deb stable main" | sudo tee /etc/apt/sources.list.d/k6.list
          sudo apt-get update
          sudo apt-get install k6

      - name: Run k6 benchmark
        run: |
          k6 run --out json=k6-results.json deployment/production/scripts/k6-benchmark.js || true

      - name: Generate benchmark report
        if: always()
        run: |
          if [ -f "k6-results.json" ]; then
            echo "## ðŸƒ API Benchmark Results" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "Benchmark completed. Check artifacts for detailed results." >> $GITHUB_STEP_SUMMARY
          else
            echo "## âš ï¸ Benchmark skipped" >> $GITHUB_STEP_SUMMARY
            echo "k6 benchmark script not found or failed." >> $GITHUB_STEP_SUMMARY
          fi

      - name: Upload benchmark results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: k6-benchmark-results
          path: k6-results.json
          if-no-files-found: ignore

  performance-summary:
    name: Performance Summary
    runs-on: ubuntu-latest
    needs: [lighthouse, bundle-analysis, api-benchmark]
    if: always()

    steps:
      - name: Generate summary
        run: |
          echo "## ðŸ“Š Performance Check Complete" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Check | Status |" >> $GITHUB_STEP_SUMMARY
          echo "|-------|--------|" >> $GITHUB_STEP_SUMMARY
          echo "| Lighthouse | ${{ needs.lighthouse.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Bundle Analysis | ${{ needs.bundle-analysis.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| API Benchmark | ${{ needs.api-benchmark.result }} |" >> $GITHUB_STEP_SUMMARY
